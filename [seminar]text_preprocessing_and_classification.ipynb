{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[seminar]text_preprocessing_and_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "11.8333px",
        "width": "160px"
      },
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "339.717px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoNanoMax/DLS/blob/main/%5Bseminar%5Dtext_preprocessing_and_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PcL7r1hqySq"
      },
      "source": [
        "# Предобработка текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-sGLT0vp4jt"
      },
      "source": [
        "## Часть 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn8EWAjnr18g"
      },
      "source": [
        "### Токенизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btBdBLxbgrNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c3aa7f-49d3-4504-e21a-0efeaf374c04"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq-QOD9NlO_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723bf4fa-e122-4681-ef22-02ff7a41b345"
      },
      "source": [
        "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
        "tokens = word_tokenize(data.lower())\n",
        "print(tokens)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFDKUzkS6Mci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2ba543-b6c0-4eac-8965-9b13c680a742"
      },
      "source": [
        "print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I was going home when she rung.', 'It was a surprise.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQoG7qznyuf5"
      },
      "source": [
        "[<img src=\"https://raw.githubusercontent.com/natasha/natasha-logos/master/natasha.svg\">](https://github.com/natasha/natasha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPeApu2mwYxY"
      },
      "source": [
        "[Razdel](https://natasha.github.io/razdel/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwJj5Z2fvbeN"
      },
      "source": [
        "!pip install -q razdel"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy58Xd_vve-z",
        "outputId": "a12ec083-e0f2-4024-a715-d9740f90f292"
      },
      "source": [
        "from razdel import tokenize, sentenize\n",
        "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'\n",
        "list(tokenize(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 13, 'Кружка-термос'),\n",
              " Substring(14, 16, 'на'),\n",
              " Substring(17, 20, '0.5'),\n",
              " Substring(20, 21, 'л'),\n",
              " Substring(22, 23, '('),\n",
              " Substring(23, 28, '50/64'),\n",
              " Substring(29, 32, 'см³'),\n",
              " Substring(32, 33, ','),\n",
              " Substring(34, 37, '516'),\n",
              " Substring(37, 38, ';'),\n",
              " Substring(38, 41, '...'),\n",
              " Substring(41, 42, ')')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrmhCpNdQo6r"
      },
      "source": [
        "#### Регулярные выражения\n",
        "\n",
        "Исчерпывающий пост https://habr.com/ru/post/349860/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IccRpcG06Mfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0648782b-72be-4580-ccf7-0c653c85b9ea"
      },
      "source": [
        "import re\n",
        "word = 'supercalifragilisticexpialidocious'\n",
        "re.findall('[abc]|super', word)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['super', 'c', 'a', 'a', 'c', 'a', 'c']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je8YPHLZPJW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f09aed8-e818-4075-fe39-e655f557abfb"
      },
      "source": [
        "re.findall('\\d{1,3}', 'These are some numbers: 49 and 432312')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['49', '432', '312']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzde8MX1PJXA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e650f9bd-b41d-4c86-b7a8-162a55f7fd25"
      },
      "source": [
        "re.sub('[,\\.?!]','','How, to? split. text!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How to split text'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyswV9nuPJXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8ece8c-1d68-4f96-d09e-0f1f5344c951"
      },
      "source": [
        "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'can', 'play', 'football']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz0wIRkRswOQ"
      },
      "source": [
        "### Удаление неинформативных слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trdPOBM2jEMf"
      },
      "source": [
        "#### N-граммы\n",
        "\n",
        "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--466CQV1q--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/78nf1vryed8h1tz05fim.gif\" height=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYEBfCxLic3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d257caf2-5e68-4229-97d2-6f44c5cf94eb"
      },
      "source": [
        "unigram = list(nltk.ngrams(tokens, 1))\n",
        "bigram = list(nltk.ngrams(tokens, 2))\n",
        "print(unigram[:5])\n",
        "print(bigram[:5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('all',), ('work',), ('and',), ('no',), ('play',)]\n",
            "[('all', 'work'), ('work', 'and'), ('and', 'no'), ('no', 'play'), ('play', 'makes')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AFeZqejmWwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68e1e68-56f1-40ab-96ed-d643b1029684"
      },
      "source": [
        "from nltk import FreqDist\n",
        "print('Популярные униграммы: ', FreqDist(unigram).most_common(5))\n",
        "print('Популярные биграммы: ', FreqDist(bigram).most_common(5))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Популярные униграммы:  [(('all',), 2), (('work',), 2), (('and',), 2), (('no',), 2), (('play',), 2)]\n",
            "Популярные биграммы:  [(('all', 'work'), 2), (('work', 'and'), 2), (('and', 'no'), 2), (('no', 'play'), 2), (('play', 'makes'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W3jJ56hnBFu"
      },
      "source": [
        "#### Стоп-слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIBwQ3nBnEfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f939d49-1ecc-4dde-dd99-6cf79dc7fb25"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1nk-TqEslRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020146fb-e570-4e48-c2a1-62a2dffb97f0"
      },
      "source": [
        "stopWords = set(stopwords.words('english'))\n",
        "print(stopWords)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'me', 'i', 's', 'not', 'in', 'your', 'being', 'same', 'such', 'ours', \"weren't\", 'further', 'some', 'it', 'when', 'with', 'you', 'shouldn', 'both', 'now', 'do', 'nor', 'this', \"isn't\", 'hadn', 'had', 'than', \"couldn't\", 'on', 'mightn', 'they', 'hasn', 'will', 'yourselves', 'about', 're', 'are', 'after', 'were', \"she's\", 'out', 'very', 'into', 'didn', 'can', 'ma', 'a', 'an', 'theirs', 'have', 'off', 'does', 'themselves', 'while', 'should', 'at', 'having', 'down', 'yours', 'these', 'which', 'under', 'am', 'her', 'did', \"it's\", 'how', 'hers', 'he', \"wasn't\", 'm', 'we', 'ain', 'haven', 'his', 'my', 'for', \"didn't\", 'been', 'there', 'wasn', 'each', 'she', 'few', 'up', 'between', \"needn't\", \"you've\", 'has', 'below', 'isn', 'that', 've', \"you'll\", 'be', 'but', \"hasn't\", 'only', 'their', 'where', \"you'd\", 'above', 'too', 'to', 'until', \"that'll\", 'and', 'once', 'most', 'before', 'weren', 'those', \"should've\", 'won', 'by', 'needn', 'ourselves', 'yourself', 'couldn', 'because', 'myself', 'again', 'here', 'just', 'other', 'y', \"mustn't\", 'through', 'so', 'd', 'o', 'them', 'any', 'no', 'll', 'aren', 'why', \"doesn't\", 'him', \"shouldn't\", 'don', 'shan', 'doing', 'then', 'what', 'during', \"hadn't\", 'the', 'herself', \"mightn't\", 'of', \"you're\", 't', 'from', 'or', 'own', 'wouldn', \"wouldn't\", 'itself', 'as', 'whom', 'is', \"shan't\", 'who', 'if', 'our', \"don't\", \"won't\", 'doesn', \"aren't\", 'himself', \"haven't\", 'mustn', 'its', 'more', 'against', 'over', 'all', 'was'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFkfJm9ktAVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16bba41f-e655-4546-cc9f-f6de6cd239a2"
      },
      "source": [
        "print([word for word in tokens if word not in stopWords])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['work', 'play', 'makes', 'jack', 'dull', 'boy', ',', 'work', 'play']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5QoqlHiS83f",
        "outputId": "127d9ffc-6445-41c2-e397-5a76259f490e"
      },
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh-MYv6e-skM"
      },
      "source": [
        "#### Стемминг vs Лемматизация\n",
        "* ‘Caring’ -> Лемматизация -> ‘Care’\n",
        "* ‘Caring’ -> Стемминг -> ‘Car’"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAUKc1oTiQjf"
      },
      "source": [
        "### Стемминг\n",
        "* процесс нахождения основы слова для заданного исходного слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRVu-TrON4sq"
      },
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "words = [\"game\", \"gaming\", \"gamed\", \"games\", \"compacted\"]\n",
        "words_ru = ['корова', 'мальчики', 'мужчины', 'столом', 'убежала']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HTGfsBN9eX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1225b47-97e2-412f-c20f-e9457c858e82"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "list(map(ps.stem, words))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['game', 'game', 'game', 'game', 'compact']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qZkB-oODkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3da533-cb19-4fa4-c91b-bb51128a36ff"
      },
      "source": [
        "ss = SnowballStemmer(language='russian')\n",
        "list(map(ss.stem, words_ru))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['коров', 'мальчик', 'мужчин', 'стол', 'убежа']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbTXbi9FJXr1"
      },
      "source": [
        "### Лематизация\n",
        "* процесс приведения словоформы к лемме — её нормальной (словарной) форме"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF4nnEz00thb"
      },
      "source": [
        "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "is no basis for a system of government.  Supreme executive power derives from\n",
        "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
        "\n",
        "raw_ru = \"\"\"Не существует научных доказательств в пользу эффективности НЛП, оно \n",
        "признано псевдонаукой. Систематические обзоры указывают, что НЛП основано на \n",
        "устаревших представлениях об устройстве мозга, несовместимо с современной \n",
        "неврологией и содержит ряд фактических ошибок.\"\"\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mljfOAC4n21I",
        "outputId": "0b4c2429-0c12-41bd-c189-fa5ab4f0e2a7"
      },
      "source": [
        "!pip install -q pymorphy2"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 55 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 8.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zez7jnXl5uJ",
        "outputId": "e5c26c67-4d13-4883-e0c4-3284e3d2ee85"
      },
      "source": [
        "# 1\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "pymorphy_results = list(map(lambda x: morph.parse(x), raw_ru.split(' ')))\n",
        "print(' '.join([res[0].normal_form for res in pymorphy_results]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "не существовать научный доказательство в польза эффективность нлп, оно \n",
            "признать псевдонаукой. систематический обзор указывают, что нлп основать на \n",
            "устаревший представление о устройство мозга, несовместимый с современный \n",
            "неврология и содержать ряд фактический ошибок.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7MDqIvWib4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed547b8-9b2e-44ba-8f20-977329c41cf9"
      },
      "source": [
        "# 2\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "spacy_results = nlp(raw)\n",
        "print(' '.join([token.lemma_ for token in spacy_results]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "denni : listen , strange woman lie in pond distribute sword \n",
            " be no basis for a system of government .   Supreme executive power derive from \n",
            " a mandate from the masse , not from some farcical aquatic ceremony .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVC5gjCRk5bD"
      },
      "source": [
        "[Сравнение PyMorphy2 и PyMystem3](https://habr.com/ru/post/503420/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yim_NVYA6MeS"
      },
      "source": [
        "### Part-of-Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t_MamYKqbSk",
        "outputId": "41954852-2236-4efb-b23a-30c6943687f4"
      },
      "source": [
        "# 1\n",
        "[(res[0].normal_form, res[0].tag) for res in pymorphy_results[:9]]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', OpencorporaTag('PRCL')),\n",
              " ('существовать', OpencorporaTag('VERB,impf,intr sing,3per,pres,indc')),\n",
              " ('научный', OpencorporaTag('ADJF,Qual plur,gent')),\n",
              " ('доказательство', OpencorporaTag('NOUN,inan,neut plur,gent')),\n",
              " ('в', OpencorporaTag('PREP')),\n",
              " ('польза', OpencorporaTag('NOUN,inan,femn sing,accs')),\n",
              " ('эффективность', OpencorporaTag('NOUN,inan,femn sing,gent')),\n",
              " ('нлп,', OpencorporaTag('UNKN')),\n",
              " ('оно', OpencorporaTag('NPRO,neut,3per,Anph sing,nomn'))]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doa85yw6JWea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f45299-b920-4c25-a0a5-3c4b7c6d7536"
      },
      "source": [
        "# 2\n",
        "[(token.lemma_, token.pos_) for token in spacy_results[:7]]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('denni', 'NOUN'),\n",
              " (':', 'PUNCT'),\n",
              " ('listen', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('strange', 'ADJ'),\n",
              " ('woman', 'NOUN'),\n",
              " ('lie', 'VERB')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVGJLVjLtFDp",
        "outputId": "8806c8d1-cc75-4ad3-ac65-f77505b62671"
      },
      "source": [
        "!pip install -q rnnmorph"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.3 MB/s \n",
            "\u001b[?25h  Building wheel for rnnmorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for russian-tagsets (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ms2yeEFqrtZ",
        "outputId": "854db582-5de9-4297-a8d5-07f4aa085a04"
      },
      "source": [
        "# 3\n",
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")\n",
        "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
        "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', 'PART', '_'),\n",
              " ('существовать',\n",
              "  'VERB',\n",
              "  'Mood=Ind|Number=Sing|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act'),\n",
              " ('научный', 'ADJ', 'Case=Gen|Degree=Pos|Number=Plur'),\n",
              " ('доказательство', 'NOUN', 'Case=Gen|Gender=Neut|Number=Plur'),\n",
              " ('в', 'ADP', '_'),\n",
              " ('польза', 'NOUN', 'Case=Acc|Gender=Fem|Number=Sing'),\n",
              " ('эффективность', 'NOUN', 'Case=Gen|Gender=Fem|Number=Sing')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Slt2R76Mgk"
      },
      "source": [
        "### Named entities recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvB43ZHT6MhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e959c2-45ac-4677-afd9-895a3df96fe8"
      },
      "source": [
        "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0-_oFwwqAwN"
      },
      "source": [
        "## Часть 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIwDfmrYOMfi"
      },
      "source": [
        "### Задача классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6DaLniC6MhY"
      },
      "source": [
        "#### 20 newsgroups\n",
        "Датасет с 18000 новостей, сгруппированных по 20 темам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uS7IJNW6Mhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e3f029-fcf5-4849-bd07-120bd01cf3a6"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMbagpJE6Mhh",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785314d2-4888-4b0e-f47b-e3f7da15536a"
      },
      "source": [
        " newsgroups_train.target_names"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QReW1K46Mhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93511a6c-1944-4f57-a7dc-06a8bb43b038"
      },
      "source": [
        "newsgroups_train.filenames.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZtRIQmNQ4H0"
      },
      "source": [
        "#### Рассмотрим подвыборку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhwuCp5B6Mhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85196dc-d5d3-4d02-88ef-05052a505000"
      },
      "source": [
        "categories = ['alt.atheism', 'talk.religion.misc',\n",
        "              'comp.graphics', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                      categories=categories)\n",
        "newsgroups_train.filenames.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOREsv336MiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd60ef27-0c16-4b8a-f270-202445f6b45c"
      },
      "source": [
        "print(newsgroups_train.data[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: rych@festival.ed.ac.uk (R Hawkes)\n",
            "Subject: 3DS: Where did all the texture rules go?\n",
            "Lines: 21\n",
            "\n",
            "Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "\n",
            "======================================================================\n",
            "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
            "Virtual Environment Laboratory\n",
            "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
            "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBnDG-TN6MiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d7dab9-bc13-44f4-d084-d6d2f0c62f0b"
      },
      "source": [
        "newsgroups_train.target[:10]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XlZYpodRYDI"
      },
      "source": [
        "#### TF-IDF(напоминание)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohUk2n3jRbNp"
      },
      "source": [
        "$n_{\\mathbb{d}\\mathbb{w}}$ - число вхождений слова $\\mathbb{w}$ в документ $\\mathbb{d}$;<br>\n",
        "$N_{\\mathbb{w}}$ - число документов, содержащих $\\mathbb{w}$;<br>\n",
        "$N$ - число документов; <br><br>\n",
        "\n",
        "$p(\\mathbb{w}, \\mathbb{d}) = N_{\\mathbb{w}} / N$ - вероятность наличия слова $\\mathbb{w}$ в любом документе $\\mathbb{d}$\n",
        "<br>\n",
        "$P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}}}$ - вероятность встретить $n_{\\mathbb{d}\\mathbb{w}}$ раз слово $\\mathbb{w}$ в документе $\\mathbb{d}$<br><br>\n",
        "\n",
        "$-\\log{P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}})} = n_{\\mathbb{d}\\mathbb{w}} \\cdot \\log{(N / N_{\\mathbb{w}})} = TF(\\mathbb{w}, \\mathbb{d}) \\cdot IDF(\\mathbb{w})$<br><br>\n",
        "\n",
        "$TF(\\mathbb{w}, \\mathbb{d}) = n_{\\mathbb{d}\\mathbb{w}}$ - term frequency;<br>\n",
        "$IDF(\\mathbb{w}) = \\log{(N /N_{\\mathbb{w}})}$ - inverted document frequency;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQvcMiFH6MiM"
      },
      "source": [
        "#### Давайте векторизуем эти тексты с помощью TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98LLAoZO6MiU"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baXLU0lj6MiY"
      },
      "source": [
        "#### Некоторые параметры: \n",
        "* input : string {‘filename’, ‘file’, ‘content’}\n",
        "*  lowercase : boolean, default True\n",
        "*  preprocessor : callable or None (default)\n",
        "*  tokenizer : callable or None (default)\n",
        "*  stop_words : string {‘english’}, list, or None (default)\n",
        "*  ngram_range : tuple (min_n, max_n)\n",
        "*  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
        "*  min_df : float in range [0.0, 1.0] or int, default=1\n",
        "*  max_features : int or None, default=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-m81BJxZFwJ"
      },
      "source": [
        "#### Перебор параметров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f7padHL6MiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce664b7-d36b-4b61-e148-ff7d85b79b8f"
      },
      "source": [
        "# lowercase\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 34118)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf2s4HCY6Mie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd4e63fe-90b3-48cd-edc3-0907d52884c6"
      },
      "source": [
        "vectorizer = TfidfVectorizer(lowercase=False)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 42307)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hwlTWapZR8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2028f03f-e517-4da0-c0fd-de2c5e362086"
      },
      "source": [
        "vectorizer.get_feature_names()[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000',\n",
              " '00000',\n",
              " '000000',\n",
              " '000005102000',\n",
              " '000021',\n",
              " '000062David42',\n",
              " '0000VEC',\n",
              " '0001']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYfpk0ds6Mij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b8fc5e-90e0-486c-f1ed-34119324c5f6"
      },
      "source": [
        "# min_df, max_df\n",
        "vectorizer = TfidfVectorizer(min_df=0.8)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ookt99atZ8sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe89656c-ab71-454a-97b8-7c68caa3f8d1"
      },
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'from', 'in', 'lines', 'of', 'organization', 'subject', 'the', 'to']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e_h6c0X6Mim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c6142d-3368-4b5c-bb47-811082637fbb"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.8)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 2391)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUhOyx4NihL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d8df7d-b0b2-465f-815d-088754acd3ec"
      },
      "source": [
        "# ngram_range\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.03, max_df=0.9)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 1236)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7074cdSF6MjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "60005ca3-ab69-42c3-c298-f8cf554002c0"
      },
      "source": [
        "# стоп-слова, preproc\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))\n",
        "nltk.download('wordnet')\n",
        "wnl = nltk.WordNetLemmatizer()\n",
        "\n",
        "def preproc_nltk(text):\n",
        "    #text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
        "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
        "\n",
        "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
        "preproc_nltk(st)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'oh , think landed miracle work , thirst hunger come conference bird'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIW3hCSy6MjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81392d74-8146-4333-a3b6-25758615beb0"
      },
      "source": [
        "%%time\n",
        "vectorizer = TfidfVectorizer(preprocessor=preproc_nltk)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.51 s, sys: 4.43 ms, total: 8.51 s\n",
            "Wall time: 8.53 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lUmyAzJEB1SU",
        "outputId": "52ce6d72-dde8-4c6a-cf21-d8330a9e352e"
      },
      "source": [
        "# preproc_spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "texts = newsgroups_train.data.copy()\n",
        "\n",
        "def preproc_spacy(text):\n",
        "    spacy_results = nlp(text)\n",
        "    return ' '.join([token.lemma_ for token in spacy_results if token.lemma_ not in stopWords])\n",
        "preproc_spacy(st)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'oh , -PRON- think -PRON- land miracle work ,   thirst hunger come conference bird'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C5Ent0nG5zj",
        "outputId": "078fd4c0-2992-4386-da19-61b0d9f71a0f"
      },
      "source": [
        "%%time\n",
        "new_texts = []\n",
        "for doc in nlp.pipe(texts, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n",
        "    new_texts.append(' '.join([tok.lemma_ for tok in doc if tok.lemma not in stopWords]))\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(new_texts)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 36 s, sys: 423 ms, total: 36.4 s\n",
            "Wall time: 53 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lXAPHZA6Mj0"
      },
      "source": [
        "#### Итоговая модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZYcRkQ86Mj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ef483d-3f3d-4473-e93b-3d02b6f2f86d"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=1000)\n",
        "vectors = vectorizer.fit_transform(new_texts)\n",
        "vectorizer.get_feature_names()[::100]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000',\n",
              " 'au',\n",
              " 'christ',\n",
              " 'even',\n",
              " 'if pron have',\n",
              " 'matter',\n",
              " 'over',\n",
              " 'quote',\n",
              " 'still',\n",
              " 'truth']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQHTlj3q6Mj6"
      },
      "source": [
        "#### Можем посмотреть на косинусную меру между векторами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo4fKtAXqCl-",
        "outputId": "839d33df-00b9-4086-da2a-deba3b156e72"
      },
      "source": [
        "vector.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA8Fn5I46Mi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d09b096-aa82-4672-cbef-a3a4f29ccf48"
      },
      "source": [
        "vector = vectors.todense()[0]\n",
        "(vector != 0).sum()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kweWqI8ztDwC",
        "outputId": "204454d3-b2bf-4ff1-986a-bc4340b452e1"
      },
      "source": [
        "import numpy as np\n",
        "np.mean(list(map(lambda x: (x != 0).sum(), vectors.todense())))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93.63765978367748"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsVQhR9y6Mj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787dd7de-14ac-4c95-9a0a-d2691d24eae2"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "type(vectors)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS2G0ZZC6MkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436d1090-08bb-4f48-dd2c-dadc9943a21b"
      },
      "source": [
        "dense_vectors = vectors.todense()\n",
        "dense_vectors.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGgb5aP76MkU"
      },
      "source": [
        "def cosine_sim(v1, v2):\n",
        "    # v1, v2 (1 x dim)\n",
        "    return np.array(v1 @ v2.T / norm(v1) / norm(v2))[0][0]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_FrKM6k6MkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99951e74-eb18-4d56-df6c-50cf4cf47518"
      },
      "source": [
        "cosine_sim(dense_vectors[0], dense_vectors[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000000000002"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1XF-isH6Mkh"
      },
      "source": [
        "cosines = []\n",
        "for i in range(10):\n",
        "    cosines.append(cosine_sim(dense_vectors[0], dense_vectors[i]))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODwgYEbe6Mkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf562ce-cd93-4b6c-d337-b01e4840caf8"
      },
      "source": [
        "# [1, 3, 2, 0, 2, 0, 2, 1, 2, 1]\n",
        "cosines"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0000000000000002,\n",
              " 0.043294587352860875,\n",
              " 0.005869835524491915,\n",
              " 0.0935800085948649,\n",
              " 0.042441093346628496,\n",
              " 0.04763556598669193,\n",
              " 0.038723466540658134,\n",
              " 0.22771527506874503,\n",
              " 0.03289646848736767,\n",
              " 0.06184884190504455]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRZyJP3c6Mkq"
      },
      "source": [
        "#### Обучим любую известную модель на полученных признаках"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RDfl72A6Mks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091ec871-2b6a-4b8d-b116-63f89085724f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(dense_vectors, newsgroups_train.target, test_size=0.2, random_state=0)\n",
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1627,), (407,))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjfwduNp6Mlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29fa580-8fbf-4109-cdf5-313c32e6eddc"
      },
      "source": [
        "%%time\n",
        "svc = svm.SVC()\n",
        "svc.fit(X_train, y_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.64 s, sys: 6.3 ms, total: 5.65 s\n",
            "Wall time: 5.64 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6Evwipx6Mlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7026ec65-5dfd-4092-a00e-706ff31b86d9"
      },
      "source": [
        "accuracy_score(y_test, svc.predict(X_test))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9213759213759214"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EBZRbXT6Mly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45c8255-67d3-4f1a-f20c-07a78f5cbb81"
      },
      "source": [
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, y_train)\n",
        "accuracy_score(y_test, sgd.predict(X_test))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8918918918918919"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5OAwBJ0LuPb"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKLGAYPvPJcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c4dd9a-676c-47d5-93d0-f9264c3c2ef6"
      },
      "source": [
        "import gensim.downloader as api\n",
        "embeddings_pretrained = api.load('glove-twitter-25')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmH3vc7FSCuP"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "proc_words = [preproc_nltk(text).split() for text in newsgroups_train.data]\n",
        "embeddings_trained = Word2Vec(proc_words, # data for model to train on\n",
        "                 size=100,                 # embedding vector size\n",
        "                 min_count=3,             # consider words that occured at least 5 times\n",
        "                 window=3).wv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lq20widPJcO"
      },
      "source": [
        "def vectorize_sum(comment, embeddings):\n",
        "    \"\"\"\n",
        "    implement a function that converts preprocessed comment to a sum of token vectors\n",
        "    \"\"\"\n",
        "    embedding_dim = embeddings.vectors.shape[1]\n",
        "    features = np.zeros([embedding_dim], dtype='float32')\n",
        "\n",
        "    for word in preproc_nltk(comment).split():\n",
        "        if word in embeddings:\n",
        "            features += embeddings[f'{word}']\n",
        "    \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1KaMKBHsSHd",
        "outputId": "65336ef9-6d63-4c40-881d-d22ca4b8b2c5"
      },
      "source": [
        "len(embeddings_trained.index2word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krjpVRsLPJcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f24b897-f3c5-4ee7-84fe-1ca5a2abeafe"
      },
      "source": [
        "X_wv = np.stack([vectorize_sum(text, embeddings_pretrained) for text in newsgroups_train.data])\n",
        "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
        "X_train_wv.shape, X_test_wv.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1627, 25), (407, 25))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWhQ007PPJcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba51dbd6-e7ef-4ed5-eac0-948d32f76a5c"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = LogisticRegression(max_iter=5000)\n",
        "wv_model = clf.fit(X_train_wv, y_train)\n",
        "accuracy_score(y_test, wv_model.predict(X_test_wv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7100737100737101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT_Rr4nOUUu8",
        "outputId": "08a28d12-283e-4eab-d80c-6208cc6ceadd"
      },
      "source": [
        "X_wv = np.stack([vectorize_sum(text, embeddings_trained) for text in newsgroups_train.data])\n",
        "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
        "X_train_wv.shape, X_test_wv.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1627, 100), (407, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVMeZBLbVMjO",
        "outputId": "653442de-cfa8-4170-bfa6-1f87e00a6e29"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "wv_model = clf.fit(X_train_wv, y_train)\n",
        "accuracy_score(y_test, wv_model.predict(X_test_wv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8402948402948403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_K8NLmDVds1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}